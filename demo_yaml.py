# -*- coding: utf-8 -*-
"""
Created on Wed Jul 25 16:10:00 2018

@author: Ash & Markus

"""

import scipy as sp
import numpy as np
import numpy.random as rnd
import sys
import distree as dst
import distree.schedulers as SL
import anytree as atr
import yaml
import logging

class Distree_Demo(dst.Distree):
    def get_taskdata_path(self, task_id):
        return self.data_path + '%s.npy' % task_id

    def save_task_data(self, taskdata_path, data, task_id, parent_id):
        data = data.copy().update(task_id=task_id, parent_id=parent_id)
        with open(taskdata_path, 'w') as f:
            yaml.dump(data, f, default_flow_style=False)

    def load_task_data(self, taskdata_path):
        with open(taskdata_path, 'r') as f:
            taskdata = yaml.load(f)
        task_id = taskdata.pop("task_id")
        parent_id = taskdata.pop("parent_id")
        return taskdata, task_id, parent_id

    def branch_path(self, parent_path, branch_num):
        return parent_path + '/%u' % branch_num

    def measure_state(state, taskdata):
        # TODO
        pass

    def generate_state_filename(taskdata):
        # TODO
        pass

    def store_state(state, taskdata={}, filename=None):
        if not filename:
            filename = generate_state_filename(taskdata)
        path = self.data_path + filename
        np.save(path, state)
        return path

    def load_state(state, taskdata):
        # TODO
        pass

    def should_branch(state, t, t_0, taskdata):
        # TODO
        pass

    def run_task(self, taskdata_path):
        #Load data saved by parent task. The taskdata file contains everything
        #needed to run the task. Initial values, parameters, and so on.
        #It also contains the task_id, generated by the scheduler when the
        #task was scheduled, and the parent_id, which may be `None`.
        taskdata, task_id, parent_id = self.load_task_data(taskdata_path)
        
        #Put some data into local variables for convenience
        t_max = taskdata['t_max']
        coeff = taskdata['coeff']
        states = taskdata["states"]
        state_data = taskdata.get("state_data", {})

        has_children = "children" in taskdata and taskdata["children"]

        if has_children:
            # TODO Decide what to do here. Maybe ask the user to set some
            # command line parameter saying "Yes, please recreate children."
            msg = "This task already has children."
            raise NotImplementedError(msg)

        t_0 = min(states)
        prev_checkpoint = max(states)
        t = prev_checkpoint
        state_path = states[t]
        state = load_state(state_path)

        try:
            prev_datapoint = max(state_data)
        except ValueError:
            prev_datapoint = -np.inf
        
        while t < t_max:
            state, t_increment = evolve_state(state, taskdata)
            t += t_increment

            if t - prev_datapoint >= taskdata["data_frequency"]:
                data_entry = measure_data(state, taskdata)
                state_data[t] = data_entry
                prev_datapoint = t

            if t - prev_checkpoint >= taskdata["checkpoint_frequency"]:
                states[t] = store_state(state, taskdata=taskdata)
                prev_checkpoint = t

            if should_branch(state, t, t_0, taskdata):
                # TODO Create children
                #taskdata = self.branch(taskdata, task_id, parent_id)
                break

        # Always store the state at the end of the simulation.
        # TODO Fix the fact that this gets run even if t > t_max from the
        # start.
        states[t] = store_state(state, taskdata=taskdata)

        #Save the final taskdata, overwriting the initial data file(s)
        taskdata["states"] = states
        tastkdata["state_data"] = state_data
        self.save_task_data(taskdata_path, taskdata, task_id, parent_id) 

    def branch(self, taskdata, task_id, parent_id):
        parent_path = taskdata['parent_path']
        branch_num = taskdata['branch_num']
        t_1 = taskdata['t_1']
        t_max = taskdata['t_max']
        state = taskdata['state']
        coeff = taskdata['coeff']

        #determine number of children
        num_children = 2
        #modify the 
        taskdata['num_children'] = 2

        #determine the child's parent branch path 
        branch_path = self.branch_path(parent_path, branch_num)

        #create taskdata files for, and schedule, children
        for child_branch in range(num_children):
            child_taskdata = {
                'parent_path': branch_path, 
                'branch_num': child_branch, 
                't_1': None, 
                't_max': t_max,
                #a new state for each child
                'state': state * (child_branch+1),
                'coeff': coeff/(child_branch+1), 
                'num_children': None
            }

            #This will assign a new task_id to each child, add their tasks to
            #the log, and schedule them to be run. How they are run is up to
            #the scheduler.
            child_id, child_path = self.schedule_task(task_id, child_taskdata)
            #NOTE: We could add more child info to the parent taskdata here

        return taskdata

#Build an anytree from saved data by parsing the log file.
def build_tree(dtree):
    top = None
    r = atr.Resolver('name')
    with open(dtree.log_path, "r") as f:
        for line in f:
            task_id1, parent_id1, taskdata_path = line.strip().split("\t")
            taskdata, task_id2, parent_id2 = dtree.load_task_data(taskdata_path)
            assert task_id1 == str(task_id2)
            assert parent_id1 == str(parent_id2)

            parent_path = taskdata['parent_path']
            branch_num = taskdata['branch_num']
            num_children = taskdata['num_children']
            
            if top is None:
                #Check that this really is a top-level node
                assert parent_id2 == "" or parent_id2 is None

                top = atr.Node('%u' % branch_num, task_id=task_id2, 
                                parent_id=parent_id2, 
                                num_children=num_children, 
                                data=taskdata)
            else:
                #pnode = atr.search.find_by_attr(top, parent_id, 
                # name='task_id') #not optimal, but should never fail

                #should be efficient 
                # (alternatively, keep a node dictionary with id's as keys)
                pnode = r.get(top, parent_path) 

                atr.Node('%u' % branch_num, parent=pnode, task_id=task_id2, 
                         parent_id=parent_id2, num_children=num_children, 
                         data=taskdata)

    return top

if __name__ == "__main__":
    logfile = "./log/distreelog.txt"
    datafolder = "./data/"
    #Create a scheduler and tell it what script to run to schedule tasks.
    sched = SL.Sched_Local(sys.argv[0], scriptargs=['--child'])

    #Create the tree object, telling it where the logfile lives, where the taskdata
    #files are to be stored, and giving it the scheduler to use.
    dtree = Distree_Demo(logfile, datafolder, sched)

    #NOTE: This script is designed so that it can schedule the root job and also
    #      child jobs, depending on the supplied command-line arguments.

    if len(sys.argv) == 1: 
        # Create the initial MPS.
        root_state = np.array([0.0])
        root_state_filename = "root_state.npy"
        root_state_path = dtree.store_state(root_mps, {},
                                            filename=root_state_filename)
         
        #Save a simple initial taskdata file and schedule a root job!
        init_task_data = {'parent_path': '', 
                          'branch_num': 0, 
                          't_max': 4, 
                          'states': {0.: root_state_path},
                          'coeff': 1.0
                          }
        rootfile = '{}root.yaml'.format(datafolder)
        dtree.save_task_data(rootfile, init_task_data, None, None)
        #The following schedules a job (it will be run in a different process)
        dtree.schedule_task_from_file(rootfile)

    elif len(sys.argv) == 2:
        if sys.argv[1] == '--show':
            #Print the tree from saved data
            top = build_tree(dtree)
            logging.info(atr.RenderTree(top))
        else:
            #Assume the single argument is a taskdata file to be used for a root job
            dtree.schedule_task_from_file(sys.argv[1])

    elif len(sys.argv) == 3:
        if sys.argv[2] == '--child':
            #Assume the first argument is a taskdata file for a child job.
            #This means the task should be run in the current process,
            #rather than be scheduled for later.
            dtree.run_task(sys.argv[1])
        else:
            logging.info("I don't know what you want from me.")

